{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import faiss\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_path = './corpus.csv',\n",
    "    model_path='./../../Notebooks/models/parallel_combined'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "df = df[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>main</th>\n",
       "      <th>court</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16735</th>\n",
       "      <td>16949</td>\n",
       "      <td>16949</td>\n",
       "      <td>Jonathan Gibbons, administrator of Hiram Kimba...</td>\n",
       "      <td>Jonathan Gibbons, administrator of Hiram Kimba...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12346</th>\n",
       "      <td>12498</td>\n",
       "      <td>12498</td>\n",
       "      <td>Caroline C. Holden et al. v. The City of Chicago</td>\n",
       "      <td>Caroline C. Holden et al. v. The City of Chica...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>12992</td>\n",
       "      <td>12992</td>\n",
       "      <td>Ludwig Baker and Caroline Baker v. Augusta Young</td>\n",
       "      <td>Ludwig Baker and Caroline Baker v. Augusta You...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>14632</td>\n",
       "      <td>14632</td>\n",
       "      <td>The National Insurance Company v. Sidney T. We...</td>\n",
       "      <td>The National Insurance Company v. Sidney T. We...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>592</td>\n",
       "      <td>592</td>\n",
       "      <td>James F. Stevenson v. Emma V. Stevenson</td>\n",
       "      <td>James F. Stevenson v. Emma V. Stevenson.\\nOpin...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  \\\n",
       "16735         16949       16949   \n",
       "12346         12498       12498   \n",
       "12830         12992       12992   \n",
       "14453         14632       14632   \n",
       "584             592         592   \n",
       "\n",
       "                                                    name  \\\n",
       "16735  Jonathan Gibbons, administrator of Hiram Kimba...   \n",
       "12346   Caroline C. Holden et al. v. The City of Chicago   \n",
       "12830   Ludwig Baker and Caroline Baker v. Augusta Young   \n",
       "14453  The National Insurance Company v. Sidney T. We...   \n",
       "584              James F. Stevenson v. Emma V. Stevenson   \n",
       "\n",
       "                                                    main  \\\n",
       "16735  Jonathan Gibbons, administrator of Hiram Kimba...   \n",
       "12346  Caroline C. Holden et al. v. The City of Chica...   \n",
       "12830  Ludwig Baker and Caroline Baker v. Augusta You...   \n",
       "14453  The National Insurance Company v. Sidney T. We...   \n",
       "584    James F. Stevenson v. Emma V. Stevenson.\\nOpin...   \n",
       "\n",
       "                        court country  text  title  \n",
       "16735  Illinois Supreme Court     USA   NaN    NaN  \n",
       "12346  Illinois Supreme Court     USA   NaN    NaN  \n",
       "12830  Illinois Supreme Court     USA   NaN    NaN  \n",
       "14453  Illinois Supreme Court     USA   NaN    NaN  \n",
       "584    Illinois Supreme Court     USA   NaN    NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 300/300 [00:00<00:00, 82.8kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.51MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 48.6kB/s]\n",
      "Downloading config.json: 100%|██████████| 740/740 [00:00<00:00, 465kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('casehold/legalbert')\n",
    "model = BertModel.from_pretrained(args.model_path, output_attentions=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True)\n",
    "\n",
    "    # embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "    attention_weights = outputs.attentions \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Determine top 10 document tokens based on attention weight \n",
    "    start_index_m = 1  # Assuming [SEP] token between query and document\n",
    "    end_index_m = start_index_m + len(tokens)\n",
    "\n",
    "    document_attention = attention_weights[-1][0, :, start_index_m:end_index_m, start_index_m:end_index_m].mean(dim=0)\n",
    "    k = min(10, len(document_attention))\n",
    "    \n",
    "    top_attentions, top_indices = torch.topk(document_attention, k)  # Get top 10 attentions and their indices\n",
    "\n",
    "    # Ensure top_indices and top_attentions are properly flattened\n",
    "    top_indices_flat = top_indices.cpu().numpy().flatten()\n",
    "    top_attentions_flat = top_attentions.cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "    top_tokens_with_weights = {tokens[idx]: float(attention) for idx, attention in zip(top_indices_flat, top_attentions_flat)}\n",
    "    stringified_weights = json.dumps(top_tokens_with_weights)\n",
    "\n",
    "    return embeddings, stringified_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the embedding lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.dropna(subset=['main'])\n",
    "df['main'].isnull().any()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f5933faf494ee5aa9268a696466063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Batches:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress = tqdm(total=len(df), desc='Train Batches', leave=True)\n",
    "\n",
    "embeddings_list = []\n",
    "attention_list = []\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    embeddings, attention_data = generate_embeddings(row['main'])\n",
    "    embeddings_list.append(embeddings)\n",
    "    attention_list.append(attention_data)\n",
    "\n",
    "    progress.update(1)\n",
    "\n",
    "embeddings_matrix = np.concatenate(embeddings_list)\n",
    "attention_array = np.array(attention_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build FAISS Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = embeddings_matrix.shape[1] # dimension of embeddings \n",
    "index = faiss.IndexFlatL2(D)\n",
    "index.add(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write index and attention data to static files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"faiss_index_file.index\")\n",
    "np.save(\"attention.npy\", attention_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_index = faiss.read_index(\"faiss_index_file.index\")\n",
    "loaded_attention = np.load(\"attention.npy\", allow_pickle=True)\n",
    "loaded_titles = df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query_embedding, k=5):\n",
    "    # Perform search using cosine similarity\n",
    "    D, I = loaded_index.search(query_embedding.numpy(), k)\n",
    "    return D, I\n",
    "\n",
    "def get_titles(indices):\n",
    "    # Retrieve corresponding titles from metadata\n",
    "    titles = [loaded_titles[i] for i in indices]\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search1(query):\n",
    "    query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    query_tokens = {key: value.to('cpu') for key, value in query_tokens.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_output = model(**query_tokens, output_attentions=True, output_hidden_states=True)\n",
    "        query_embedding = query_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "\n",
    "        q_tokens = tokenizer.tokenize(query)\n",
    "\n",
    "        query_attention = query_output.attentions\n",
    "        last_layer_attention = query_attention[-1]\n",
    "        query_attention_weights = last_layer_attention[0,1:1+len(q_tokens),1:1+len(q_tokens)].mean(dim=0).cpu().numpy()\n",
    "        query_attention_matrix_serialized = json.dumps(query_attention_weights.tolist())\n",
    "\n",
    "    # Perform search\n",
    "    D, I = loaded_index.search(query_embedding, 10)\n",
    "\n",
    "    # OR \n",
    "\n",
    "    D, I = loaded_index.search(query_embedding.reshape(1,-1), 10)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Document:\n",
      "--------------\n",
      "Title:  The City of Elmhurst, Appellee, vs. William J. Buettgen, Appellant\n",
      "Distances: [[67.054665 68.089966 68.14056  68.42929  68.8322   69.070335 69.51305\n",
      "  69.63351  69.759514 70.0788  ]]\n",
      "Nearest Neighbor Titles:\n",
      "1. The People of the State of Illinois, Defendant in Error, vs. Wayne Jeffers, Plaintiff in Error\n",
      "2. Charles J. Meadowcroft et al. v. The People of the State of Illinois\n",
      "3. Charles T. Schueler et al. v. Joseph Mueller\n",
      "4. Chicago, Burlington and Quincy Railroad Co. v. Clara M. Harwood\n",
      "5. Margarett Williams, Appellee, vs. Chalon Garvin et al., Appellants\n",
      "6. The City of Dixon v. Eli B. Baker\n",
      "7. Louis Glanz v. Charles S. Gloeckler\n",
      "8. Beatrice Fitch et al. v. Joseph H. Gray et al.\n",
      "9. Hiram H. Rosencrantz v. William W. Mason\n"
     ]
    }
   ],
   "source": [
    "query = 'murder'\n",
    "query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "query_tokens = {key: value.to('cpu') for key, value in query_tokens.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    query_output = model(**query_tokens, output_attentions=True, output_hidden_states=True)\n",
    "    query_embedding = query_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "\n",
    "    q_tokens = tokenizer.tokenize(query)\n",
    "\n",
    "    query_attention = query_output.attentions\n",
    "    last_layer_attention = query_attention[-1]\n",
    "    query_attention_weights = last_layer_attention[0,1:1+len(q_tokens),1:1+len(q_tokens)].mean(dim=0).cpu().numpy()\n",
    "    query_attention_matrix_serialized = json.dumps(query_attention_weights.tolist())\n",
    "    \n",
    "\n",
    "# Perform search\n",
    "distances, indices = search(query_embedding, 10)\n",
    "\n",
    "print(indices)\n",
    "\n",
    "# Retrieve corresponding titles\n",
    "titles = get_titles(indices[0])\n",
    "\n",
    "print(\"Distances:\", distances)\n",
    "print(\"--------------\")\n",
    "print(\"Nearest Neighbor Titles:\")\n",
    "for i, title in enumerate(titles[0:], start=1):  # Skip the first title as it's the query document\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
