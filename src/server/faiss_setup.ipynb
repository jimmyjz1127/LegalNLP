{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data \n",
    "Raw corpus must be a comma delimited CSV file with the following columns:\n",
    "1. **name** : name of the document \n",
    "2. **main** : the main text of the document (what will be encoded and searched against)\n",
    "3. **court** : OPTIONAL court that is associated with document \n",
    "4. **country** : OPTIONAL country of origin of document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_path = './corpus.csv',\n",
    "    model_path='./../../Notebooks/models/multi_parallel',\n",
    "    faiss_index_path = './faiss_index_file.index'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cleaned_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['idx'] = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For breaking down each document into subchunks to account for BERT 512 token size limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakdown_documents(documents):\n",
    "    keys = ['name','court', 'country', 'court','idx']\n",
    "\n",
    "    new_documents = [] \n",
    "\n",
    "    for index, document in documents.iterrows():\n",
    "        if type(document['main']) == type(1.5): continue\n",
    "        if len(document['main']) > 1024:\n",
    "            sections = breakdown_document(document['main'])\n",
    "\n",
    "            for section in sections:\n",
    "                obj = {} \n",
    "                obj['main'] = section\n",
    "                for key in keys:\n",
    "                    obj[key] = document[key]\n",
    "                new_documents.append(obj)\n",
    "        else:\n",
    "            new_documents.append(document.to_dict())\n",
    "\n",
    "    return pd.DataFrame(new_documents)\n",
    "                \n",
    "\n",
    "\n",
    "def breakdown_document(document, max_length=1024, stride = 128):\n",
    "    def find_split_index(s, start):\n",
    "        end = min(start + max_length, len(s))\n",
    "\n",
    "        if end == len(s): return len(s)\n",
    "\n",
    "        split_index = s.rfind(' ', start, end)\n",
    "        return split_index if split_index != -1 else end\n",
    "\n",
    "    sections = []\n",
    "    start = 0\n",
    "    while start < len(document):\n",
    "        split_index = find_split_index(document, start)\n",
    "        sections.append(document[start:split_index].strip())\n",
    "        # start = split_index + 1 if split_index < len(paragraph) else len(paragraph)\n",
    "\n",
    "        if start + stride >= len(document) or split_index >= len(document): break\n",
    "\n",
    "        next_start = document.rfind(' ', start, start+stride)\n",
    "\n",
    "        start = next_start + 1 if next_start != -1 else len(document)\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = breakdown_documents(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>main</th>\n",
       "      <th>court</th>\n",
       "      <th>country</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26702.0</td>\n",
       "      <td>The Central Illinois Public Service Company et...</td>\n",
       "      <td>(No. 25992.\\nThe Central Illinois Public Servi...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Grant Johnson v. The People of the State of Il...</td>\n",
       "      <td>Grant Johnson v. The People of the State of Il...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Grant Johnson v. The People of the State of Il...</td>\n",
       "      <td>acknowledgment of guilt. A confession is a vol...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Grant Johnson v. The People of the State of Il...</td>\n",
       "      <td>in their nature.\\n2. Same—when giving of instr...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Grant Johnson v. The People of the State of Il...</td>\n",
       "      <td>free and voluntary confession of guilt is the ...</td>\n",
       "      <td>Illinois Supreme Court</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               name  \\\n",
       "0     26702.0  The Central Illinois Public Service Company et...   \n",
       "1         NaN  Grant Johnson v. The People of the State of Il...   \n",
       "2         NaN  Grant Johnson v. The People of the State of Il...   \n",
       "3         NaN  Grant Johnson v. The People of the State of Il...   \n",
       "4         NaN  Grant Johnson v. The People of the State of Il...   \n",
       "\n",
       "                                                main                   court  \\\n",
       "0  (No. 25992.\\nThe Central Illinois Public Servi...  Illinois Supreme Court   \n",
       "1  Grant Johnson v. The People of the State of Il...  Illinois Supreme Court   \n",
       "2  acknowledgment of guilt. A confession is a vol...  Illinois Supreme Court   \n",
       "3  in their nature.\\n2. Same—when giving of instr...  Illinois Supreme Court   \n",
       "4  free and voluntary confession of guilt is the ...  Illinois Supreme Court   \n",
       "\n",
       "  country  idx  \n",
       "0     USA    0  \n",
       "1     USA    1  \n",
       "2     USA    1  \n",
       "3     USA    1  \n",
       "4     USA    1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name ./../../Notebooks/models/combined/mlm_combined. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text):\n",
    "    embeddings = model.encode(text, convert_to_tensor=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the embedding lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e739a81ccb40cc86e305460f7f9356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Batches:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress = tqdm(total=len(df), desc='Train Batches', leave=True)\n",
    "\n",
    "embeddings_list = []\n",
    "attention_list = []\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    embeddings = generate_embeddings(row['main'])\n",
    "    embeddings_list.append(embeddings)\n",
    "\n",
    "    progress.update(1)\n",
    "\n",
    "embeddings_matrix = np.concatenate([embedding.cpu().numpy() for embedding in embeddings_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build FAISS Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_matrix = np.stack([embedding.cpu().numpy() for embedding in embeddings_list])\n",
    "D = embeddings_matrix.shape[1]  # dimension of embeddings\n",
    "index = faiss.IndexFlatL2(D)\n",
    "index.add(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = embeddings_matrix.shape# dimension of embeddings \n",
    "# index = faiss.IndexFlatL2(D)\n",
    "# index.add(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write index and attention data to static files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"faiss_index_file.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_index = faiss.read_index(\"faiss_index_file.index\")\n",
    "loaded_titles = df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query_embedding, k=100):\n",
    "    # Perform search using cosine similarity\n",
    "    D, I = loaded_index.search(query_embedding.numpy(), k)\n",
    "    return D, I\n",
    "\n",
    "def get_titles(indices):\n",
    "    # Retrieve corresponding titles from metadata\n",
    "    titles = [loaded_titles[i] for i in indices]\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7609  875 6797 8645 1306 8652 3736 9827 5714 3687]]\n",
      "Distances: [[128.51797 136.04918 138.59277 141.84715 143.4627  144.2062  144.7921\n",
      "  144.85117 145.04272 146.1094 ]]\n",
      "--------------\n",
      "Nearest Neighbor Titles:\n",
      "1. The People of the State of Illinois ex rel. Henry Booth, v. Charles E. Lippincott, Auditor\n",
      "2. The Santa Clara Female Academy v. Francis J. Sullivan et al.\n",
      "3. The People of the State of Illinois, ex relatione The Merchants’ Savings, Loan and Trust Company of Chicago, v. The Auditor of Public Accounts\n",
      "4. Charles Howard v. John W. Lakin\n",
      "5. The Western Union Telegraph Company v. The Chicago and Paducah Railroad Company et al.\n",
      "6. John Dolese et al. v. Daniel A. Pierce\n",
      "7. The City of Olney v. J. N. Concur et al.\n",
      "8. The W. Scheidel Coil Company, Appellant, vs. James A. Rose, Secretary of State, Appellee\n",
      "9. Samuel Voris et al. v. William Renshaw, Jr.\n",
      "10. The Illinois Starch Company v. The Ottawa Hydraulic Company\n"
     ]
    }
   ],
   "source": [
    "query = 'license'\n",
    "\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "query_embedding = query_embedding.unsqueeze(0)\n",
    "\n",
    "distances, indices = search(query_embedding.cpu(), 10)\n",
    "print(indices)\n",
    "\n",
    "titles = get_titles(indices[0])\n",
    "\n",
    "print(\"Distances:\", distances)\n",
    "print(\"--------------\")\n",
    "print(\"Nearest Neighbor Titles:\")\n",
    "for i, title in enumerate(titles[0:], start=1):  \n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The People of the State of Illinois ex rel. Henry Booth, v. Charles E. Lippincott, Auditor.\\nCircuit judges of Cook county—salaries of, urider the constitution of 1870. The circuit judges of Cook county elected under the constitution of 1870 were entitled to receive from the State, until the adjournment of the first session, of the general assembly after the adoption of such constitution, a salary of $1000 per annum, only, as provided h}' the constitution of 1848.\\nMr. W. C. Goudy, for the relator.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.iloc[7609]['main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
