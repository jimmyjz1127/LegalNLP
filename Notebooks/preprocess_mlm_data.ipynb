{"cells":[{"cell_type":"markdown","id":"-3csdqPUlP8S","metadata":{"id":"-3csdqPUlP8S"},"source":["# For preparing fine-tuning data for MLM (Masked Language Modelling)"]},{"cell_type":"code","execution_count":1,"id":"gor6XhomVjw8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8928,"status":"ok","timestamp":1705857693523,"user":{"displayName":"Jimmy Zhang","userId":"02236096453379548022"},"user_tz":0},"id":"gor6XhomVjw8","outputId":"948b9d9a-5ba5-40be-d0b7-dfca46a10373"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/jz75/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import os\n","import json\n","import re\n","import string\n","import random\n","import time\n","import datetime\n","import numpy as np\n","import pandas as pd\n","from argparse import Namespace\n","\n","# from transformers import BertTokenizer\n","import transformers\n","from transformers import BertTokenizer, BertModel, BertConfig\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from transformers import BertForSequenceClassification, AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import pipeline\n","from transformers import BertTokenizer, DataCollatorForLanguageModeling\n","\n","import torch\n","import random\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"markdown","id":"PVtjhTL3VhYW","metadata":{"id":"PVtjhTL3VhYW"},"source":["Prepare configurations for data preparation"]},{"cell_type":"code","execution_count":19,"id":"c485ccf9","metadata":{"id":"c485ccf9"},"outputs":[],"source":["args = Namespace(\n","    raw_data_filename = 'aus_sum_cases_train.json',\n","    raw_data_path = \"./raw_data/summary_data/\",\n","    processed_data_path = \"./processed_data\",\n","    max_segment_length = 512,\n","    max_samples = 4000,\n","    mode = 'a', # a : append, w : write,\n",")"]},{"cell_type":"markdown","id":"9f0f5c6c","metadata":{"id":"9f0f5c6c"},"source":["## Ingest Raw Data"]},{"cell_type":"markdown","id":"955c9dca","metadata":{"id":"955c9dca"},"source":["Format :\n","{\\\n","    &nbsp;&nbsp; query\\\n","    &nbsp;&nbsp; text \\\n","    &nbsp;&nbsp; topic_label\\\n","    &nbsp;&nbsp; secondary_query\\\n","    &nbsp;&nbsp; label\\\n","}"]},{"cell_type":"code","execution_count":7,"id":"6a299f11","metadata":{},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('casehold/legalbert')"]},{"cell_type":"markdown","id":"b47913ec","metadata":{"id":"b47913ec"},"source":["### Using NLTK for tokenization"]},{"cell_type":"code","execution_count":87,"id":"dba0fd88","metadata":{},"outputs":[],"source":["def extract_sentences_json(all_sentences):\n","\n","    # with open('./raw_data/r_legaladvice_train.json', 'r') as json_file:\n","    #     json_data = json.load(json_file)\n","    with open('./raw_data/summary_data/aus_sum_cases_train.json', 'r') as json_file:\n","        json_data = json.load(json_file)\n","    counter = 0\n","\n","    for item in json_data:\n","        if counter >= args.max_samples : break \n","\n","        sentences = nltk.sent_tokenize(item['text']) + nltk.sent_tokenize(item['query'])\n","\n","        i = 0 \n","        while i < len(sentences):\n","            sentence = sentences[i]\n","            i += 1\n","            counter += 1\n","\n","            tokens = tokenizer.tokenize(sentence)\n","\n","            if len(tokens) >= 510 or len(tokens) < 5 : continue\n","            if counter >= args.max_samples : break \n","            all_sentences.append(sentence)\n","\n","    print(counter)\n","    print(len(all_sentences))"]},{"cell_type":"code","execution_count":71,"id":"e8db345d","metadata":{},"outputs":[],"source":["def extract_sentences_casehold(all_sentences):\n","    casehold_df = pd.read_csv('./processed_data/casehold_processed.csv')\n","    counter = 0\n","\n","    for index,row in casehold_df.iterrows():\n","        \n","        if counter >= args.max_samples : break \n","\n","        sentences = nltk.sent_tokenize(row['context'])\n","\n","        i = 0 \n","        while i < len(sentences):\n","            sentence = sentences[i]\n","            counter+=1\n","            i += 1\n","\n","            tokens = tokenizer.tokenize(sentence)\n","\n","            if len(tokens) >= 510 or len(tokens) < 5 : continue\n","            if counter >= args.max_samples : break \n","            all_sentences.append(sentence)\n","    print(counter)\n","    print(len(all_sentences))"]},{"cell_type":"code","execution_count":72,"id":"3ddc330f","metadata":{},"outputs":[],"source":["def extract_sentences_ledgar(all_sentences):\n","    df = pd.read_json('./processed_data/LEDGAR_2016-2019_clean.jsonl', lines=True)\n","\n","    counter = 0\n","    for index,row in df.iterrows(): \n","        \n","        if counter >= args.max_samples : break \n","\n","        sentences = nltk.sent_tokenize(row['provision'])\n","\n","        i = 0 \n","        while i < len(sentences):\n","            sentence = sentences[i]\n","\n","            i += 1\n","            counter += 1 \n","            tokens = tokenizer.tokenize(sentence)\n","\n","            if len(tokens) >= 510 or len(tokens) < 5 : continue\n","            if counter >= args.max_samples : break \n","            all_sentences.append(sentence)\n","\n","    print(counter)\n","    print(len(all_sentences))"]},{"cell_type":"code","execution_count":83,"id":"6433eabb","metadata":{},"outputs":[],"source":["all_sentences = []"]},{"cell_type":"code","execution_count":88,"id":"4d69a8d0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4000\n","14263\n"]}],"source":["extract_sentences_json(all_sentences)"]},{"cell_type":"code","execution_count":85,"id":"270f326e","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4000\n","7282\n"]}],"source":["extract_sentences_casehold(all_sentences)"]},{"cell_type":"code","execution_count":86,"id":"c132a286","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4000\n","11270\n"]}],"source":["extract_sentences_ledgar(all_sentences)"]},{"cell_type":"markdown","id":"015b7fc3","metadata":{"id":"015b7fc3"},"source":["## Process/Prepare Raw Data"]},{"cell_type":"code","execution_count":89,"id":"f294bfa0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1705857919608,"user":{"displayName":"Jimmy Zhang","userId":"02236096453379548022"},"user_tz":0},"id":"f294bfa0","outputId":"d44fccf9-b4c2-4454-ffb7-9a80eb43db75"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The title says most of it.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I just heard back from a friend of some people...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>We’ll call them Cafe Mooby.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Cafe Mooby stayed open until the last minute, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>From my experiences with my company, I was all...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence\n","0                         The title says most of it.\n","1  I just heard back from a friend of some people...\n","2                        We’ll call them Cafe Mooby.\n","3  Cafe Mooby stayed open until the last minute, ...\n","4  From my experiences with my company, I was all..."]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.DataFrame(all_sentences, columns=['sentence'])\n","\n","df.head()"]},{"cell_type":"code","execution_count":90,"id":"12f91de0","metadata":{},"outputs":[{"data":{"text/plain":["14263"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["len(df)"]},{"cell_type":"code","execution_count":91,"id":"ecb83ce9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1705857953179,"user":{"displayName":"Jimmy Zhang","userId":"02236096453379548022"},"user_tz":0},"id":"ecb83ce9","outputId":"ae1e60d9-db1b-4f42-b717-477305657c9c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>(c) Roth IRA's.--Paragraph (4) of section 408A...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>For example, the State Constitution provides t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>See Capco of Summerville, Inc. v. J.H.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>New York - Mother Terrorizing Family</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>at 701 (&lt;HOLDING&gt;); see also United Parcel Ser...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence\n","0  (c) Roth IRA's.--Paragraph (4) of section 408A...\n","1  For example, the State Constitution provides t...\n","2             See Capco of Summerville, Inc. v. J.H.\n","3               New York - Mother Terrorizing Family\n","4  at 701 (<HOLDING>); see also United Parcel Ser..."]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["df = df.sample(frac=1).reset_index(drop=True)\n","df.head()"]},{"cell_type":"code","execution_count":92,"id":"c7a4617a","metadata":{"id":"c7a4617a"},"outputs":[],"source":["# Save data to file\n","df.to_csv(args.processed_data_path + '/sentences.csv', mode='w')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
