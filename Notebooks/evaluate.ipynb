{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 17:40:22.281417: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 17:40:23.116669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from argparse import Namespace\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from datasets import Dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, DataCollatorForLanguageModeling\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_path = './processed_data/combined_ir.csv',\n",
    "    base_model_path='jimmyjz1127/multi_parallel',\n",
    "    model_save_path = './models/multi_parallel_mlm_test2',\n",
    "    max_samples=15000,\n",
    "    train_split=0.7,\n",
    "    epochs = 5,\n",
    "    freeze=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.data_path)[0:args.max_samples]\n",
    "num_train_rows = int(len(df) * (1 - args.train_split)//2) - 1\n",
    "df['split'] = 'train'\n",
    "df.loc[:num_train_rows, 'split'] = 'val'\n",
    "df.loc[num_train_rows:num_train_rows + num_train_rows, 'split'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Split      : 10501\n",
      "Length of Train Validation : 2249\n",
      "Length of Train Test       : 2250\n"
     ]
    }
   ],
   "source": [
    "print('Length of Train Split      :', len(df[df['split'] == 'train']))\n",
    "print('Length of Train Validation :', len(df[df['split'] == 'val']))\n",
    "print('Length of Train Test       :', len(df[df['split'] == 'test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('casehold/legalbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz75/Documents/2023-2024/SH-Project/CS4099-LegalNLP/pytorchenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "############## Setup Train Dataloader ##############\n",
    "####################################################\n",
    "\n",
    "encoded_data_train = [tokenizer.encode_plus(row['query'], row['result'], add_special_tokens=True, max_length=512, pad_to_max_length=True, truncation=True) for index,row in df[df['split'] == 'train'].iterrows()]\n",
    "input_ids_train = [item['input_ids'] for item in encoded_data_train]\n",
    "attention_masks_train = [item['attention_mask'] for item in encoded_data_train]\n",
    "labels_train = [row['label'] for index,row in df[df['split'] == 'train'].iterrows()]\n",
    "\n",
    "# Convert to tensors\n",
    "input_ids_train = torch.tensor(input_ids_train)\n",
    "attention_masks_train = torch.tensor(attention_masks_train)\n",
    "labels_train = torch.tensor(labels_train)\n",
    "\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=16, shuffle=True) # NOTE : maybe set pin_memory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "############## Setup Val Dataloader ################\n",
    "####################################################\n",
    "\n",
    "encoded_data_val = [tokenizer.encode_plus(row['query'], row['result'], add_special_tokens=True, max_length=512, pad_to_max_length=True, truncation=True) for index,row in df[df['split'] == 'val'].iterrows()]\n",
    "input_ids_val = [item['input_ids'] for item in encoded_data_val]\n",
    "attention_masks_val = [item['attention_mask'] for item in encoded_data_val]\n",
    "labels_val = [row['label'] for index,row in df[df['split'] == 'val'].iterrows()]\n",
    "\n",
    "# Convert to tensors\n",
    "input_ids_val = torch.tensor(input_ids_val)\n",
    "attention_masks_val = torch.tensor(attention_masks_val)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "\n",
    "# Create a dataset\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=16, shuffle=True) # NOTE : maybe set pin_memory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "############## Setup Test Dataloader ##############\n",
    "###################################################\n",
    "\n",
    "encoded_data_test = [tokenizer.encode_plus(row['query'], row['result'], add_special_tokens=True, max_length=512, pad_to_max_length=True, truncation=True) for index,row in df[df['split'] == 'test'].iterrows()]\n",
    "input_ids_test = [item['input_ids'] for item in encoded_data_test]\n",
    "attention_masks_test = [item['attention_mask'] for item in encoded_data_test]\n",
    "labels_test = [row['label'] for index,row in df[df['split'] == 'test'].iterrows()]\n",
    "\n",
    "# Convert to tensors\n",
    "input_ids_test = torch.tensor(input_ids_test)\n",
    "attention_masks_test = torch.tensor(attention_masks_test)\n",
    "labels_test = torch.tensor(labels_test)\n",
    "\n",
    "# Create a dataset\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=16, shuffle=True) # NOTE : maybe set pin_memory=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "############ Train Routine Utility Functions ############\n",
    "#########################################################\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    y_target = y_target.cpu()\n",
    "    y_pred_indices = (torch.sigmoid(y_pred)>0.5).cpu().long()#.max(dim=1)[1]\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100\n",
    "\n",
    "\n",
    "def calculate_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fine-tune routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import AdamW\n",
    "\n",
    "'''\n",
    "TRAINING SETUP\n",
    "'''\n",
    "# Check if CUDA acceleration is available \n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "# Initialize model with sequence classification head \n",
    "model = BertForSequenceClassification.from_pretrained(args.base_model_path)\n",
    "\n",
    "# Conditoinally freeze core encoder layers\n",
    "if args.freeze:\n",
    "  for param in model.base_model.parameters():\n",
    "    param.requires_grad  = False\n",
    "  model.classifier = torch.nn.Linear(model.config.hidden_size, 2)\n",
    "  optimizer = AdamW(model.classifier.parameters(), lr=5e-5)\n",
    "else:\n",
    "  optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=len(dataloader_train) * 0.05, num_training_steps=len(dataloader_train) * args.epochs)\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())\n",
    "\n",
    "print('============================================')\n",
    "\n",
    "train_progress = tqdm(total=0, desc='Train Batches', leave=True)\n",
    "validation_progress = tqdm(total=0, desc='Validation Batches', leave=True)\n",
    "epoch_progress = tqdm(total=args.epochs, desc='Epoch', leave=True)\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "patience = 3\n",
    "num_epochs_no_improvement = 0\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "TRAINING LOOP\n",
    "'''\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "  model.train()\n",
    "  total_train_loss = 0\n",
    "  total_train_accuracy = 0 #NEW\n",
    "\n",
    "  train_progress.reset(total=len(dataloader_train))\n",
    "  validation_progress.reset(total=len(dataloader_val))\n",
    "\n",
    "  for step, batch in enumerate(dataloader_train):\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n",
    "\n",
    "    model.zero_grad()\n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    total_train_loss += loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    logits = outputs.logits.detach().cpu().numpy()#NEW\n",
    "    label_ids = b_labels.to('cpu').numpy()#NEW\n",
    "    total_train_accuracy += calculate_accuracy(logits, label_ids)#NEW\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    train_progress.update(1)\n",
    "\n",
    "  avg_train_loss = total_train_loss / len(dataloader_train)\n",
    "  print(f'Epoch {epoch}: Average Training Loss: {avg_train_loss}')\n",
    "\n",
    "  model.eval()\n",
    "  total_eval_accuracy = 0\n",
    "  total_eval_loss = 0\n",
    "\n",
    "  for batch in dataloader_val:\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_input_ids, b_input_mask, b_labels = b_input_ids.to(device), b_input_mask.to(device), b_labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs.logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    total_eval_loss += loss_fn(outputs.logits.squeeze(-1), b_labels).item() # perhaps just outputs.loss (need to include labels as parameter in model() above)\n",
    "\n",
    "    total_eval_accuracy += calculate_accuracy(logits, label_ids)\n",
    "\n",
    "    validation_progress.update(1)\n",
    "\n",
    "  avg_val_accuracy = total_eval_accuracy / len(dataloader_val)\n",
    "  print(f'Epoch {epoch}: Validation Accuracy: {avg_val_accuracy}')\n",
    "\n",
    "  # Checkpointing and Early Stopping\n",
    "  if avg_val_accuracy > best_val_accuracy:\n",
    "      print(f'Validation accuracy improved from {best_val_accuracy} to {avg_val_accuracy}. Saving model...')\n",
    "      best_val_accuracy = avg_val_accuracy\n",
    "      num_epochs_no_improvement = 0\n",
    "      # Save the model using save_pretrained\n",
    "      model.save_pretrained(args.model_save_path)\n",
    "  else:\n",
    "      num_epochs_no_improvement += 1\n",
    "      if num_epochs_no_improvement >= patience:\n",
    "          print(\"Early stopping triggered.\")\n",
    "          break  # Exit the training loop\n",
    "\n",
    "  epoch_progress.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig, AutoModel\n",
    "def evaluate_sequence_pair_class(model_path,  title):\n",
    "    '''\n",
    "    Routine for evaluating model for sequence pair classification\n",
    "    '''\n",
    "    batch_progress = tqdm(total=len(dataloader_test), desc='Batches', leave=True)\n",
    "\n",
    "    # load model and tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    device = 'cpu'\n",
    "\n",
    "    # Check if cuda available\n",
    "    if torch.cuda.is_available():\n",
    "        # model.to('cuda')\n",
    "        device = 'cuda'\n",
    "\n",
    "    print(device)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    print('Evaluating ' + f'[{title}]')\n",
    "    print('============================================')\n",
    "\n",
    "\n",
    "    with torch.no_grad(): # disable calculating gradients (more efficient for evaluation)\n",
    "        for batch in dataloader_test:\n",
    "            input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).flatten() # find index of max value in logits tensor (where each index corresponds to a binary class)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            batch_progress.update(1)\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, acc = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
    "    print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual Entailment Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d591f62405ba48aaa8c70342e8b6bceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Evaluating [TE Model]\n",
      "============================================\n",
      "Accuracy: 0.8768888888888889\n",
      "Precision: 0.857331571994716\n",
      "Recall: 0.793398533007335\n",
      "F1 Score: 0.8241269841269842\n"
     ]
    }
   ],
   "source": [
    "evaluate_sequence_pair_class('jimmyjz1127/te_model_test',  'TE Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla bert-base-uncased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcf6a57410d470581fccbca854c3378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Evaluating [bert-base-uncased]\n",
      "============================================\n",
      "Accuracy: 0.8342222222222222\n",
      "Precision: 0.8060522696011004\n",
      "Recall: 0.7163814180929096\n",
      "F1 Score: 0.7585760517799353\n"
     ]
    }
   ],
   "source": [
    "evaluate_sequence_pair_class('jimmyjz1127/base_test',  'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Multi-Task Model With Further MLM Pre-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ca5605bc8a47c4a40763997be44a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Evaluating [Parallel Multi-Task With Further MLM Pre-training]\n",
      "============================================\n",
      "Accuracy: 0.8897777777777778\n",
      "Precision: 0.9930795847750865\n",
      "Recall: 0.7017114914425427\n",
      "F1 Score: 0.8223495702005731\n"
     ]
    }
   ],
   "source": [
    "evaluate_sequence_pair_class('jimmyjz1127/multi_parallel_mlm_test',  'Parallel Multi-Task With Further MLM Pre-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selective Question & Answering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ceff39b31234d09a59a8b4d857830bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Evaluating [QA Model]\n",
      "============================================\n",
      "Accuracy: 0.7577777777777778\n",
      "Precision: 0.7922912205567452\n",
      "Recall: 0.45232273838630804\n",
      "F1 Score: 0.5758754863813229\n"
     ]
    }
   ],
   "source": [
    "evaluate_sequence_pair_class('jimmyjz1127/qa_test',  'QA Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Multi-Task Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dba0dae30df4a5eaec8777e3b3c2478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Evaluating [Sequential Multi-Task Model]\n",
      "============================================\n",
      "Accuracy: 0.8395555555555556\n",
      "Precision: 0.8278335724533716\n",
      "Recall: 0.7053789731051344\n",
      "F1 Score: 0.7617161716171618\n"
     ]
    }
   ],
   "source": [
    "evaluate_sequence_pair_class('jimmyjz1127/test_combined_base',  'Sequential Multi-Task Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Multi-Task Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5993ceee640146068474e1a5d5ebde56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Evaluating [Parallel Multi-Task]\n",
      "============================================\n",
      "Accuracy: 0.9075555555555556\n",
      "Precision: 0.9856687898089171\n",
      "Recall: 0.7567237163814181\n",
      "F1 Score: 0.8561549100968188\n"
     ]
    }
   ],
   "source": [
    "evaluate_sequence_pair_class('jimmyjz1127/combined/multitask_parallel',  'Parallel Multi-Task')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
